# Implementation of RAG along with Bloom 1b1 LLM for better response
This repository contains a LLM project focused on producing better responses for questions on "Attention Is All You Need" Paper. 
The project leverages the PyTroch framework to use a pretrained LLM along with RAG for providing better responses. 

## Data Source
The project utilizes the "Attention Is All You Need" Paper, which is publicly available at following URL: [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)

## Project Overview
The core of the project is to learn on how to implement RAG for a pretrained LLM. 
The model is pretrained and publicly available on HuggingFace at following URL: [https://huggingface.co/bigscience/bloom-1b1](https://huggingface.co/bigscience/bloom-1b1)
The Jupyter Notebook included in this repository provides a detailed walkthrough of the RAG implementation.

## Data Acquisition and Preparation: 
To replicate the project results, it is necessary to download the paper from the specified URL.
Ensure that the extracted data files are placed in the same directory as the Jupyter Notebook for data loading.

## Note: 
The project code assumes that the required data files are present in the same directory as the Jupyter Notebook. Please follow the instructions above to acquire and prepare the data accordingly.
